## **About**
Hello, I am a Master's student in [NLP&AI Lab.](http://nlp.korea.ac.kr/) advised by Prof. [Heuiseok Lim](https://scholar.google.com/citations?user=HMTkz7oAAAAJ&hl=en) in the Department of Computer Science and Engineering at [Korea University](https://www.korea.edu/mbshome/mbs/en/index.do). I received the B.S degree from Hongik University with majors in Mechanical Engineering and Computer Science. I am studying Natural Language Processing, focusing on Information Retrieval (IR) and Retrieval-Augmented Generation (RAG) systems. I aim to make AI models more beneficial to humans and society.
 

 

## **Education**
M.S. in Computer Science and Engineering, Korea University  
_Mar. 2025 - Current_

B.S. in Mechanical Engineering and Computer Science, Hongik University  
_Mar. 2020 - Feb. 2025_

 

## **Papers**
[**Improving Korean-English Cross-Lingual Retrieval: A Data-Centric Study of Language Composition and Model Merging**](https://arxiv.org/abs/2507.08480)  
**Youngjoon Jang**, Junyoung Son, Taemin Lee, Seongtae Hong, Heuiseok Lim  
_ArXiv_

[**From Ambiguity to Accuracy: The Transformative Effect of Coreference Resolution on Retrieval-Augmented Generation systems**](https://arxiv.org/abs/2507.07847)  
**Youngjoon Jang**, Seongtae Hong, Junyoung Son, Sungjin Park, Chanjun Park, Heuiseok Lim  
_ACL 2025 SRW_

[**Where am I? Large Language Models Wandering between Semantics and Structures in Long Contexts**](https://aclanthology.org/2024.emnlp-main.783/)  
Seonmin Koo, Jinsung Kim, **Youngjoon Jang**, Chanjun Park, Heuiseok Lim  
_EMNLP 2024_

[**Building Korean Embedding Benchmarks with Large Language Models**](https://koreascience.kr/article/CFKO202404272002852.page)  
Junyoung Son, **Youngjoon Jang**, Soonwoo Choi, Byeonggoo Lee, Taemin Lee, Heuiseok Lim  
_Annual Conference on Human & Cognitive Language Technology (HCLT) 2024_

[**KoE5: A New Dataset and Model for Improving Korean Embedding Performance**](https://koreascience.kr/article/CFKO202404272001146.page)  
**Youngjoon Jang**, Junyoung Son, Chanjun Park, Soonwoo Choi, Byeonggoo Lee, Taemin Lee, Heuiseok Lim  
_Annual Conference on Human & Cognitive Language Technology (HCLT) 2024_

 

## **Projects**
**KULLM DeepResearch Project**     
Built a Search pipeline in open DeepResearch project.  
_2025 - Current_

[**KURE Project**](https://github.com/nlpai-lab/KURE)  
Trained a SOTA Korean retrieval embedding model and built a evaluation framework for Korean embedding models.  
_2024 - Current_

**KT-Korea University Collaborative Research**  
Trained a Korean legal domain LLM with Korean legal alignment data.  
_2024 - 2025_

[**Pre:Ranker Project**](https://github.com/yjoonjang/PreRanker)  
Trained a reranker to reduce the scope of available tools based on a given query.  
_2024 - 2025_

**URACLE-Korea University Collaborative Research**  
Trained English-Korean cross-lingual retrieval embedding model. [[Paper](https://arxiv.org/abs/2507.08480)]  
_2024 - 2025_

 

## **Open-source Contributions**
[**sentence-transformers**](https://github.com/UKPLab/sentence-transformers)  
- Contributed to the sentence-transformers library to support ListMLE, PListMLE Loss on Rerankers. [[Link](https://github.com/tomaarsen/sentence-transformers/pull/6)] 

[**Massive Text Embedding Benchmark (MTEB)**](https://github.com/embeddings-benchmark/mteb)  
- Contributed to the MTEB library with Korean retrieval evaluation datasets. [[Link](https://github.com/embeddings-benchmark/mteb/pull/1388)]  
- Added long context support for OpenAI embedding models. [[Link](https://github.com/embeddings-benchmark/mteb/pull/1526)]  
- Added support for loading jasper model in bf16 precision. [[Link](https://github.com/embeddings-benchmark/mteb/pull/2481)]  

[**FlagEmbedding**](https://github.com/FlagOpen/FlagEmbedding)  
- Contributed to the FlagEmbedding library fixing a bug related to knowledge distillation when training. [[Link](https://github.com/FlagOpen/FlagEmbedding/issues/1170)]  

 

 

 

 

 



